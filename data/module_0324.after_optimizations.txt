HloModule cluster_33__XlaCompiledKernel_true__XlaNumConstantArgs_13__XlaNumResourceArgs_0_.217

%fused_computation (param_0.1: s64[2], param_1.6: f32[2,80,28,28], param_2.4: f32[80]) -> f32[2,28,28] {
  %constant_29 = f32[] constant(0.5), metadata={op_type="Sigmoid" op_name="tower-pred-0/output/masks"}
  %broadcast.3 = f32[2,28,28]{2,1,0} broadcast(f32[] %constant_29), dimensions={}, metadata={op_type="Sigmoid" op_name="tower-pred-0/output/masks"}
  %param_1.6 = f32[2,80,28,28]{3,2,1,0} parameter(1)
  %param_2.4 = f32[80]{0} parameter(2)
  %broadcast.2 = f32[2,80,28,28]{3,2,1,0} broadcast(f32[80]{0} %param_2.4), dimensions={1}, metadata={op_type="BiasAdd" op_name="tower-pred-0/maskrcnn/conv/BiasAdd"}
  %add.3 = f32[2,80,28,28]{3,2,1,0} add(f32[2,80,28,28]{3,2,1,0} %param_1.6, f32[2,80,28,28]{3,2,1,0} %broadcast.2), metadata={op_type="BiasAdd" op_name="tower-pred-0/maskrcnn/conv/BiasAdd"}
  %iota.1 = s32[2,1]{1,0} iota(), iota_dimension=0, metadata={op_type="Pack" op_name="tower-pred-0/stack_1"}
  %param_0.1 = s64[2]{0} parameter(0)
  %convert.0 = s32[2]{0} convert(s64[2]{0} %param_0.1), metadata={op_type="Cast" op_name="tower-pred-0/Cast_2"}
  %constant_28 = s32[] constant(-1)
  %broadcast.1 = s32[2]{0} broadcast(s32[] %constant_28), dimensions={}
  %add.2 = s32[2]{0} add(s32[2]{0} %convert.0, s32[2]{0} %broadcast.1), metadata={op_type="Sub" op_name="tower-pred-0/sub_1"}
  %bitcast.3 = s32[2,1]{1,0} bitcast(s32[2]{0} %add.2), metadata={op_type="Pack" op_name="tower-pred-0/stack_1"}
  %concatenate.0 = s32[2,2]{1,0} concatenate(s32[2,1]{1,0} %iota.1, s32[2,1]{1,0} %bitcast.3), dimensions={1}, metadata={op_type="Pack" op_name="tower-pred-0/stack_1"}
  %gather.0 = f32[2,28,28]{2,1,0} gather(f32[2,80,28,28]{3,2,1,0} %add.3, s32[2,2]{1,0} %concatenate.0), offset_dims={1,2}, collapsed_slice_dims={0,1}, start_index_map={0,1}, index_vector_dim=1, slice_sizes={1,1,28,28}, metadata={op_type="GatherNd" op_name="tower-pred-0/GatherNd"}
  %multiply.1 = f32[2,28,28]{2,1,0} multiply(f32[2,28,28]{2,1,0} %broadcast.3, f32[2,28,28]{2,1,0} %gather.0), metadata={op_type="Sigmoid" op_name="tower-pred-0/output/masks"}
  %tanh.0 = f32[2,28,28]{2,1,0} tanh(f32[2,28,28]{2,1,0} %multiply.1), metadata={op_type="Sigmoid" op_name="tower-pred-0/output/masks"}
  %multiply.0 = f32[2,28,28]{2,1,0} multiply(f32[2,28,28]{2,1,0} %broadcast.3, f32[2,28,28]{2,1,0} %tanh.0), metadata={op_type="Sigmoid" op_name="tower-pred-0/output/masks"}
  ROOT %add.1 = f32[2,28,28]{2,1,0} add(f32[2,28,28]{2,1,0} %broadcast.3, f32[2,28,28]{2,1,0} %multiply.0), metadata={op_type="Sigmoid" op_name="tower-pred-0/output/masks"}
}

%fused_computation.1 (param_0.3: f32[2,256,28,28], param_1.9: f32[256]) -> f32[2,256,28,28] {
  %constant_30 = f32[] constant(0), metadata={op_type="AvgPool" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/AvgPool"}
  %broadcast.5 = f32[2,256,28,28]{3,2,1,0} broadcast(f32[] %constant_30), dimensions={}, metadata={op_type="Relu" op_name="tower-pred-0/maskrcnn/deconv/Relu"}
  %param_0.3 = f32[2,256,28,28]{3,2,1,0} parameter(0)
  %param_1.9 = f32[256]{0} parameter(1)
  %broadcast.4 = f32[2,256,28,28]{3,2,1,0} broadcast(f32[256]{0} %param_1.9), dimensions={1}, metadata={op_type="BiasAdd" op_name="tower-pred-0/maskrcnn/deconv/BiasAdd"}
  %add.4 = f32[2,256,28,28]{3,2,1,0} add(f32[2,256,28,28]{3,2,1,0} %param_0.3, f32[2,256,28,28]{3,2,1,0} %broadcast.4), metadata={op_type="BiasAdd" op_name="tower-pred-0/maskrcnn/deconv/BiasAdd"}
  ROOT %maximum.0 = f32[2,256,28,28]{3,2,1,0} maximum(f32[2,256,28,28]{3,2,1,0} %broadcast.5, f32[2,256,28,28]{3,2,1,0} %add.4), metadata={op_type="Relu" op_name="tower-pred-0/maskrcnn/deconv/Relu"}
}

%fused_computation.2 (param_0.5: s64[2], param_1.11: f32[2,256,14,14], param_2.9: f32[14,14]) -> f32[2,256,14,14] {
  %param_1.11 = f32[2,256,14,14]{1,3,2,0} parameter(1)
  %param_2.9 = f32[14,14]{1,0} parameter(2)
  %broadcast.6 = f32[2,256,14,14]{1,3,2,0} broadcast(f32[14,14]{1,0} %param_2.9), dimensions={2,3}, metadata={op_type="AvgPool" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/AvgPool"}
  %divide.0 = f32[2,256,14,14]{1,3,2,0} divide(f32[2,256,14,14]{1,3,2,0} %param_1.11, f32[2,256,14,14]{1,3,2,0} %broadcast.6), metadata={op_type="AvgPool" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/AvgPool"}
  %param_0.5 = s64[2]{0} parameter(0)
  ROOT %gather.1 = f32[2,256,14,14]{3,2,1,0} gather(f32[2,256,14,14]{1,3,2,0} %divide.0, s64[2]{0} %param_0.5), offset_dims={1,2,3}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,256,14,14}, metadata={op_type="GatherV2" op_name="tower-pred-0/multilevel_roi_align_1/output"}
}

%add_F32.72 (lhs.73: f32[], rhs.74: f32[]) -> f32[] {
  %lhs.73 = f32[] parameter(0)
  %rhs.74 = f32[] parameter(1)
  ROOT %add.75 = f32[] add(f32[] %lhs.73, f32[] %rhs.74)
}

%fused_computation.3 () -> f32[14,14] {
  %constant_31 = f32[] constant(1), metadata={op_type="AvgPool" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/AvgPool"}
  %broadcast.7 = f32[28,28]{1,0} broadcast(f32[] %constant_31), dimensions={}, metadata={op_type="AvgPool" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/AvgPool"}
  %constant_32 = f32[] constant(0), metadata={op_type="AvgPool" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/AvgPool"}
  ROOT %reduce-window.0 = f32[14,14]{1,0} reduce-window(f32[28,28]{1,0} %broadcast.7, f32[] %constant_32), window={size=2x2 stride=2x2}, to_apply=%add_F32.72, metadata={op_type="AvgPool" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/AvgPool"}
}

%add_F32.63 (lhs.64: f32[], rhs.65: f32[]) -> f32[] {
  %lhs.64 = f32[] parameter(0)
  %rhs.65 = f32[] parameter(1)
  ROOT %add.66 = f32[] add(f32[] %lhs.64, f32[] %rhs.65)
}

%fused_computation.4 (param_0.10: f32[2,28,28,256]) -> f32[2,256,14,14] {
  %param_0.10 = f32[2,28,28,256]{3,2,1,0} parameter(0)
  %bitcast.4 = f32[2,256,28,28]{1,3,2,0} bitcast(f32[2,28,28,256]{3,2,1,0} %param_0.10), metadata={op_type="Transpose" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/crop_and_resize/transpose_1"}
  %constant_33 = f32[] constant(0), metadata={op_type="AvgPool" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/AvgPool"}
  ROOT %reduce-window.1 = f32[2,256,14,14]{1,3,2,0} reduce-window(f32[2,256,28,28]{1,3,2,0} %bitcast.4, f32[] %constant_33), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%add_F32.63, metadata={op_type="AvgPool" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/AvgPool"}
}

%fused_computation.5 (param_0.13: s32[2], param_1.19: s64[2,1]) -> s64[2] {
  %param_1.19 = s64[2,1]{1,0} parameter(1)
  %bitcast.5 = s64[2]{0} bitcast(s64[2,1]{1,0} %param_1.19), metadata={op_type="StridedSlice" op_name="tower-pred-0/output/strided_slice_2"}
  %param_0.13 = s32[2]{0} parameter(0)
  %gather.2 = s64[2]{0} gather(s64[2]{0} %bitcast.5, s32[2]{0} %param_0.13), offset_dims={}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1}, metadata={op_type="GatherV2" op_name="tower-pred-0/output/GatherV2"}
  %constant_34 = s64[] constant(1), metadata={op_type="Add" op_name="tower-pred-0/output/labels"}
  %broadcast.8 = s64[2]{0} broadcast(s64[] %constant_34), dimensions={}, metadata={op_type="Add" op_name="tower-pred-0/output/labels"}
  ROOT %add.5 = s64[2]{0} add(s64[2]{0} %gather.2, s64[2]{0} %broadcast.8), metadata={op_type="Add" op_name="tower-pred-0/output/labels"}
}

ENTRY %cluster_33__XlaCompiledKernel_true__XlaNumConstantArgs_13__XlaNumResourceArgs_0_.217 (arg0.1: s64[2,1], arg1.2: s32[2], arg2.3: f32[2,28,28,256], arg3.4: s64[2], arg4.5: f32[3,3,256,256], arg5.6: f32[256], arg6.7: f32[3,3,256,256], arg7.8: f32[256], arg8.9: f32[3,3,256,256], arg9.10: f32[256], arg10.11: f32[3,3,256,256], arg11.12: f32[256], arg12.13: f32[2,2,256,256], arg13.14: f32[256], arg14.15: f32[1,1,256,80], arg15.16: f32[80]) -> (s64[2], f32[2,28,28]) {
  %arg1.2 = s32[2]{0} parameter(1), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg0.1 = s64[2,1]{1,0} parameter(0), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.5 = s64[2]{0} fusion(s32[2]{0} %arg1.2, s64[2,1]{1,0} %arg0.1), kind=kLoop, calls=%fused_computation.5, metadata={op_type="Add" op_name="tower-pred-0/output/labels"}
  %arg3.4 = s64[2]{0} parameter(3), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg2.3 = f32[2,28,28,256]{3,2,1,0} parameter(2), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.4 = f32[2,256,14,14]{1,3,2,0} fusion(f32[2,28,28,256]{3,2,1,0} %arg2.3), kind=kLoop, calls=%fused_computation.4, metadata={op_type="AvgPool" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/AvgPool"}
  %fusion.3 = f32[14,14]{1,0} fusion(), kind=kLoop, calls=%fused_computation.3, metadata={op_type="AvgPool" op_name="tower-pred-0/multilevel_roi_align_1/roi_level2/roi_align/AvgPool"}
  %fusion.2 = f32[2,256,14,14]{3,2,1,0} fusion(s64[2]{0} %arg3.4, f32[2,256,14,14]{1,3,2,0} %fusion.4, f32[14,14]{1,0} %fusion.3), kind=kLoop, calls=%fused_computation.2, metadata={op_type="GatherV2" op_name="tower-pred-0/multilevel_roi_align_1/output"}
  %arg4.5 = f32[3,3,256,256]{3,2,1,0} parameter(4), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %copy.6 = f32[3,3,256,256]{1,0,2,3} copy(f32[3,3,256,256]{3,2,1,0} %arg4.5), metadata={op_name="XLA_Args"}
  %arg5.6 = f32[256]{0} parameter(5), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %custom-call.12 = (f32[2,256,14,14]{3,2,1,0}, u8[6554624]{0}) custom-call(f32[2,256,14,14]{3,2,1,0} %fusion.2, f32[3,3,256,256]{1,0,2,3} %copy.6, f32[256]{0} %arg5.6), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_01io->bf01, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_type="Conv2D" op_name="tower-pred-0/maskrcnn/fcn0/Conv2D"}, backend_config="{\"algorithm\":\"6\",\"tensorOpsEnabled\":true,\"activationMode\":\"2\",\"convResultScale\":1}"
  %get-tuple-element.12 = f32[2,256,14,14]{3,2,1,0} get-tuple-element((f32[2,256,14,14]{3,2,1,0}, u8[6554624]{0}) %custom-call.12), index=0
  %arg6.7 = f32[3,3,256,256]{3,2,1,0} parameter(6), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %copy.7 = f32[3,3,256,256]{1,0,2,3} copy(f32[3,3,256,256]{3,2,1,0} %arg6.7), metadata={op_name="XLA_Args"}
  %arg7.8 = f32[256]{0} parameter(7), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %custom-call.13 = (f32[2,256,14,14]{3,2,1,0}, u8[6554624]{0}) custom-call(f32[2,256,14,14]{3,2,1,0} %get-tuple-element.12, f32[3,3,256,256]{1,0,2,3} %copy.7, f32[256]{0} %arg7.8), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_01io->bf01, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_type="Conv2D" op_name="tower-pred-0/maskrcnn/fcn1/Conv2D"}, backend_config="{\"algorithm\":\"6\",\"tensorOpsEnabled\":true,\"activationMode\":\"2\",\"convResultScale\":1}"
  %get-tuple-element.13 = f32[2,256,14,14]{3,2,1,0} get-tuple-element((f32[2,256,14,14]{3,2,1,0}, u8[6554624]{0}) %custom-call.13), index=0
  %arg8.9 = f32[3,3,256,256]{3,2,1,0} parameter(8), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %copy.8 = f32[3,3,256,256]{1,0,2,3} copy(f32[3,3,256,256]{3,2,1,0} %arg8.9), metadata={op_name="XLA_Args"}
  %arg9.10 = f32[256]{0} parameter(9), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %custom-call.14 = (f32[2,256,14,14]{3,2,1,0}, u8[6554624]{0}) custom-call(f32[2,256,14,14]{3,2,1,0} %get-tuple-element.13, f32[3,3,256,256]{1,0,2,3} %copy.8, f32[256]{0} %arg9.10), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_01io->bf01, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_type="Conv2D" op_name="tower-pred-0/maskrcnn/fcn2/Conv2D"}, backend_config="{\"algorithm\":\"6\",\"tensorOpsEnabled\":true,\"activationMode\":\"2\",\"convResultScale\":1}"
  %get-tuple-element.14 = f32[2,256,14,14]{3,2,1,0} get-tuple-element((f32[2,256,14,14]{3,2,1,0}, u8[6554624]{0}) %custom-call.14), index=0
  %arg10.11 = f32[3,3,256,256]{3,2,1,0} parameter(10), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %copy.9 = f32[3,3,256,256]{1,0,2,3} copy(f32[3,3,256,256]{3,2,1,0} %arg10.11), metadata={op_name="XLA_Args"}
  %arg11.12 = f32[256]{0} parameter(11), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %custom-call.15 = (f32[2,256,14,14]{3,2,1,0}, u8[6554624]{0}) custom-call(f32[2,256,14,14]{3,2,1,0} %get-tuple-element.14, f32[3,3,256,256]{1,0,2,3} %copy.9, f32[256]{0} %arg11.12), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_01io->bf01, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_type="Conv2D" op_name="tower-pred-0/maskrcnn/fcn3/Conv2D"}, backend_config="{\"algorithm\":\"6\",\"tensorOpsEnabled\":true,\"activationMode\":\"2\",\"convResultScale\":1}"
  %get-tuple-element.15 = f32[2,256,14,14]{3,2,1,0} get-tuple-element((f32[2,256,14,14]{3,2,1,0}, u8[6554624]{0}) %custom-call.15), index=0
  %arg12.13 = f32[2,2,256,256]{3,2,1,0} parameter(12), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %copy.10 = f32[2,2,256,256]{1,0,2,3} copy(f32[2,2,256,256]{3,2,1,0} %arg12.13), metadata={op_name="XLA_Args"}
  %custom-call.10 = (f32[2,256,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,256,14,14]{3,2,1,0} %get-tuple-element.15, f32[2,2,256,256]{1,0,2,3} %copy.10), window={size=2x2 stride=2x2}, dim_labels=bf01_01io->bf01, custom_call_target="__cudnn$convBackwardInput", metadata={op_type="Conv2DBackpropInput" op_name="tower-pred-0/maskrcnn/deconv/conv2d_transpose"}, backend_config="{\"algorithm\":\"1\",\"tensorOpsEnabled\":true,\"convResultScale\":1}"
  %get-tuple-element.10 = f32[2,256,28,28]{3,2,1,0} get-tuple-element((f32[2,256,28,28]{3,2,1,0}, u8[0]{0}) %custom-call.10), index=0
  %arg13.14 = f32[256]{0} parameter(13), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.1 = f32[2,256,28,28]{3,2,1,0} fusion(f32[2,256,28,28]{3,2,1,0} %get-tuple-element.10, f32[256]{0} %arg13.14), kind=kLoop, calls=%fused_computation.1, metadata={op_type="Relu" op_name="tower-pred-0/maskrcnn/deconv/Relu"}
  %arg14.15 = f32[1,1,256,80]{3,2,1,0} parameter(14), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %copy.11 = f32[1,1,256,80]{1,0,2,3} copy(f32[1,1,256,80]{3,2,1,0} %arg14.15), metadata={op_name="XLA_Args"}
  %custom-call.11 = (f32[2,80,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,256,28,28]{3,2,1,0} %fusion.1, f32[1,1,256,80]{1,0,2,3} %copy.11), window={size=1x1}, dim_labels=bf01_01io->bf01, custom_call_target="__cudnn$convForward", metadata={op_type="Conv2D" op_name="tower-pred-0/maskrcnn/conv/Conv2D"}, backend_config="{\"convResultScale\":1}"
  %get-tuple-element.11 = f32[2,80,28,28]{3,2,1,0} get-tuple-element((f32[2,80,28,28]{3,2,1,0}, u8[0]{0}) %custom-call.11), index=0
  %arg15.16 = f32[80]{0} parameter(15), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion = f32[2,28,28]{2,1,0} fusion(s64[2]{0} %fusion.5, f32[2,80,28,28]{3,2,1,0} %get-tuple-element.11, f32[80]{0} %arg15.16), kind=kLoop, calls=%fused_computation, metadata={op_type="Sigmoid" op_name="tower-pred-0/output/masks"}
  ROOT %tuple.216 = (s64[2]{0}, f32[2,28,28]{2,1,0}) tuple(s64[2]{0} %fusion.5, f32[2,28,28]{2,1,0} %fusion), metadata={op_name="XLA_Retvals"}
}

